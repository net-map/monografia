\chapter{Machine Learning}\label{chp:ml}

\section{Tratamento dos dados}\label{sec:data1}

\subsection{Dados obtidos da UCI}
	Para grande parte dos testes de  \textbf{\textit{Cross-Validation}}, foi usado um dataset obtido por meio do repositório online da UCI, desenvolvido em \cite{uji}. 
	
	
\subsection{Dados do Servidor}	






\section{Formato dos dados tratados}
A matriz de dados tratados usada diretamente pelos algoritmos de ML tem o seguinte formato:


\begin{blockarray}{cccccc}
$ZoneID$ & $BSSID_1$ & $BSSID_2$ & ... &  $BSSID_n$ \\
\begin{block}{(ccccc)c}
  1&-70 & -92 &   ... &-87&  $ Measure_1$ \\
  2&-89 & -80 & ... & -63&    $Measure_2 $\\
  3&-28 & -120 & ...&   -35& $Measure_3$ \\
   \vdots& \vdots &  \vdots & $\ddots$ &  \vdots &    \vdots \\
  1&-48 & -36 & ... &   -29&  $Measure_n$ \\
\end{block}
\end{blockarray}
 
\section{\textit{Cross-Validation} para os Modelos Usados}

A chamada \textit{Cross-Validation} dos modelos de ML é o teste para encontrar os parâmetros ótimos para o treinamento. O método escolhido de \textit{Cross-Validation} foi o \textit{K-Fold}. O método \textit{K-Fold} divide o dataset em $K$ subconjuntos de igual tamanho e então um dos conjuntos é usado como validação do treinamento feito pelos $K-1$ subconjuntos restantes. O processo é repetido $K$ vezes e em cada subdivisão possível podem ser usados valores de parâmetros de treino distintos. 

\subsection{KNN : K-Nearest-Neighbors }


Para o algoritmo de KNN, foi usado o método \textit{K-Fold} com $K=10$. O método foi aplicado duas vezes. Na primeira o modelo de KNN foi treinado com os cálculos de distância usando-se a distância Euclidiana, e variando-se o valor de $K$ do número de vizinhos em cada  \textit{fold}. Então, foi feito o mesmo processo, mas com a distância de Manhattan. Os resultados são mostrados a seguir:


\begin{figure}[H]
\centering
\caption{Erros para uso da distância Euclidiana}
 \includegraphics[width=0.9\textwidth]{euclidianKNNCrossVal2zonas}
\label{fig:euclidian}  
\end{figure}


\begin{figure}[H]
	\centering
	\caption{Erros para uso da distância Manhattan}
  \includegraphics[width=0.9\textwidth]{manhattanKNNCrossVAl2zonas}
\label{fig:manhattan}  

\end{figure}


Podemos concluir então que (1) o erro é menor no geral com a distância de Manhattan e (2) o valor de K que minimiza o erro fica entre 2 e 4 vizinhos.
No restante do trabalho foi escolhido o valor de $K=3$ vizinhos.
\subsection{Rede Neural}

Para a \textit{Cross-Validation} das Redes Neurais, também foi usado o método de  \textit{K-Fold} com $K=10$. Para cada uns dos \textit{folds} foi testado um número de neurônios em uma  \textit{hidden-layer} única. (Outros testes mostraram não valer a pena para o nosso problema usar mais de uma camada de  \textit{hidden layer} ou \textit{deep learning}). Os resultados são mostrados a seguir:



\begin{figure}[!ht]
	\centering
	\caption{Erro para diversas quantidades de neurônios na rede neural.}
  \includegraphics[width=0.9\textwidth]{CROSSVALE4ZonasNNCERTO}
\label{fig:crossNN}  

\end{figure}




Concluímos que o número ideal de neurônios na  \textit{hidden-layer} está próximo de 200. E é esse valor que usaremos daqui para frente.





\section{Métodos de Votação}

Os chamados sistemas de \textit{Ensenble Learning} são aqueles em que diversos modelos de ML são treinados e então é feito um sistema de votação para que a classificação final seja feita. No nosso sistema experimentamos com 2 modelos de votação diferentes, documentados a seguir.


\subsection{Votação Simples}

Na votação simples os resultados da classificação de todos os modelos são contabilizados e é escolhido aquele com o maior número de ocorrências entre os classificadores. Os testes foram feitos calculando-se o erro de validação no MESMO dataset de treino com uma quantidade cada vez maior de pontos de treino, estes retirados de um dataset de treino também fixado.


A votação simples foi  testada com os algoritmos de Rede Neural, KNN e SVM



\begin{figure}[!ht]
	\centering
	\caption{Erro de votação simples para uma quantidade crescente de pontos de treino.}
  \includegraphics[width=0.9\textwidth]{VoteError2zonesUCI}
\label{fig:simpleVote}  

\end{figure}


Para comparação, foram calculados os erros de validação independentes de cada um dos algoritmos usados.


\begin{figure}[!ht]
	\centering
	\caption{Erro do algoritmo KNN  para uma quantidade crescente de pontos de treino.}
  \includegraphics[width=0.9\textwidth]{KNNerror2zonesUCI}
\label{fig:crossKNN}  

\end{figure}


\begin{figure}[!ht]
	\centering
	\caption{Erro da Rede Neural  para uma quantidade crescente de pontos de treino.}
  \includegraphics[width=0.9\textwidth]{NNerror2zonesUCI}
\label{fig:crossNN2}  

\end{figure}



\begin{figure}[!ht]
	\centering
	\caption{Erro do algoritmo SVM  para uma quantidade crescente de pontos de treino.}
  \includegraphics[width=0.9\textwidth]{SVMerror2zonesUCI}
\label{fig:crossSVM}  

\end{figure}





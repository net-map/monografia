\chapter{Machine Learning}\label{chp:ml}

\section{Tratamento dos dados}\label{sec:data1}

\subsection{Dados obtidos do Repositório UCI}
	Para grande parte dos testes de  \textbf{\textit{Cross-Validation}}, foi usado   \textbf{\textit{dataset}}  UJIIndoorLoc apresentado em \cite{uji}. O  \textbf{\textit{dataset}}  consiste em diversas medidas de potência de sinal Wi-Fi medidas com diversos aparelhos celulares em 3 prédios diferentes de uma faculdade. As medidas estão separadas por prédio, andar e sala. Para os fins dessa monografia, serão realizados testes com medidas sempre de um mesmo andar, afim de classificar as zonas de um mesmo ambiente. 
	
	
\subsection{Dados do Servidor}	






\section{Formato dos dados tratados}
A matriz de dados tratados usada diretamente pelos algoritmos de ML tem o seguinte formato:


\begin{blockarray}{cccccc}
$ZoneID$ & $BSSID_1$ & $BSSID_2$ & ... &  $BSSID_n$ \\
\begin{block}{(ccccc)c}
  1&-70 & -92 &   ... &-87&  $ Measure_1$ \\
  2&-89 & -80 & ... & -63&    $Measure_2 $\\
  3&-28 & -120 & ...&   -35& $Measure_3$ \\
   \vdots& \vdots &  \vdots & $\ddots$ &  \vdots &    \vdots \\
  1&-48 & -36 & ... &   -29&  $Measure_n$ \\
\end{block}
\end{blockarray}
 
Cada coluna representa a medida de uma \textit{BSSID} (i.e. um Roteador), ou seja, uma \textit{feature} para o ML, e cada linha é um ponto de treino (i.e.  uma medida para cada  \textit{BSSID}, nossas \textit{features}).
 
 
\section{Modelos Usados e \textit{Cross-Validation} de parâmetros }

A chamada \textit{Cross-Validation} dos modelos de ML é o teste para encontrar os parâmetros ótimos para o treinamento. Um dos métodos escolhidos de \textit{Cross-Validation} foi o \textit{K-Fold}. O método \textit{K-Fold} divide o dataset em $K$ subconjuntos de igual tamanho e então um dos conjuntos é usado como validação do treinamento feito pelos $K-1$ subconjuntos restantes. O processo é repetido $K$ vezes e em cada subdivisão possível podem ser usados valores de parâmetros de treino distintos. O restante dos testes foram feitos da maneira padrão em sistemas de ML, o chamado método do \textit{Validation Set}: Dividindo-se o  \textbf{\textit{dataset}} em 80\% de pontos de treino e 20\% de pontos de validação, e então realizando respectivamente o treino e os testes com esses subconjuntos. Para essa última modalidade de \textit{Cross-Validation} foram feitos também testes em que se usava o subconjunto de 20\% para testes, mas uma quantidade crescente dos pontos de treino para o treinamento dos modelos (e.g. 10,15,20,25,30,35,40 ... até o total dos 80\%), e em cada treinamento calcula-se a taxa de erro. 

\subsection{KNN : K-Nearest-Neighbors }


Para o algoritmo de KNN, foram feitos dois testes de \textit{Cross-Validation}. No primeiro, a métrica de distância foi decidida, e no segundo, o número de vizinhos ($K$).
Para que fosse definida a métrica de distância, foi usado o método  \textit{K-Fold}  com $K=2$. E em cada \textit{fold} o modelo foi treinado com uma métrica diferente. Foram calculados 20 conjuntos diferentes de \textit{folds} e foi tirada a média do erro de validação para cada uma das métricas.


\begin{figure}[H]
\centering
\caption{Erros para uso de Diferentes Distâncias}
 \includegraphics[width=0.9\textwidth]{euclidianManhattanknn21zonas}
\label{fig:euclidian}  
\end{figure}


Depois, foi usado o método  \textit{K-Fold} com $K=10$ para a decisão do número de vizinhos. Foram testados os valores de 1 até 10 para o número de vizinhos. Na imagem a seguir vemos detalhes desse teste.


\begin{figure}[H]
\centering
\caption{Erro em função do número de vizinhos}
 \includegraphics[width=0.9\textwidth]{CrossValKNN25zonasvalorK}
\label{fig:euclidian}  
\end{figure}



Podemos concluir então que (1) o erro é menor no geral com a distância de Manhattan e (2) o valor de K que minimiza o erro fica proximo de 4 vizinhos.
No restante do trabalho foi escolhido o valor de $K=4$ vizinhos.
\subsection{Rede Neural}

Para a \textit{Cross-Validation} das Redes Neurais, também foi usado o método de  \textit{K-Fold} com $K=10$. Para cada uns dos \textit{folds} foi testado um número de neurônios em uma  \textit{hidden-layer} única. (Outros testes mostraram não valer a pena para o nosso problema usar mais de uma camada de  \textit{hidden layer} ou \textit{deep learning}). Os resultados são mostrados a seguir:



\begin{figure}[!ht]
	\centering
	\caption{Erro para diversas quantidades de neurônios na rede neural.}
  \includegraphics[width=0.9\textwidth]{CROSSVALE4ZonasNNCERTO}
\label{fig:crossNN}  

\end{figure}




Concluímos que o número ideal de neurônios na  \textit{hidden-layer} está próximo de 200. E é esse valor que usaremos daqui para frente.

\subsection{Arvore de decisão}


Baseado no trabalho apresentado por \cite{comparative}, foi escolhida uma implementação do algoritmo C4.5 \cite{quinlan} em Java, da biblioteca Weka, para serem geradas árvores de decisão. Os métodos porém foram chamados pela interface da Weka para R, chamada RWeka.
A função J48 do Weka foi testada com o os pontos de treino referentes ao primeiro andar do prédio 1 (i.e. BuildingID 1, FloorID 0)  do dataset UJIIndoorLoc. Foi levantada a curva de erro de classificação para uma quantidade crescente de pontos de treino (como explicado em 2.3).


\begin{figure}[H]
\centering
\caption{Erro em função do número de vizinhos}
 \includegraphics[width=0.9\textwidth]{J48Validacaopredio1andar0}
\label{fig:euclidian}  
\end{figure}

\subsubsection{Acoplamento com o Algoritmo AdaBoost}




\textit{Boosting} é a ideia em ML de criar uma predição forte e precisa combinando diversas previsões mais fracas. O algoritmo AdaBoost \cite{adaboost} é um método para melhorar a precisão de classificadores fracos (i.e. \textit{Weak Learners}) por meio de uma votação ponderada que leva em conta o erro de votadores fracos treinados no processo, que, por prova, se torna um classificador forte \cite{explainingadaboost}. Por definição, um classificador fraco é aquele que consistentemente consegue ser melhor que um chute para a classificação (e.g. o erro é menor que 50\% para o caso de duas classes possíveis de classificação).

Também baseados em \cite{comparative} e \cite{comparativeEN}. Usaremos o algoritmo AdaBoost  e sua implementação na biblioteca Weka para melhorar a precisão das árvores de decisão C4.5. A seguir vemos um gráfico comparando a classificação para o mesmo andar do dataset UJIIndoorLoc com os mesmos pontos de teste e uma quantidade crescente de pontos de treino, assim como feito no tópico anterior.


\begin{figure}[H]
\centering
\caption{Comparação do C.45 com o uso do AdaBoost}
 \includegraphics[width=0.9\textwidth]{J48xADAValidacaopredio1andar0}
\label{fig:euclidian}  
\end{figure}


Podemos notar que com um número grande de pontos de treino, obtemos uma melhora sensível de precisão para a classificação, e portanto, no restante do trabalho, iremos usar o algoritmo C.45 acoplado com o algoritmo AdaBoost.




\section{Métodos de Votação}

Os chamados sistemas de \textit{Ensemble Learning} são aqueles em que uma classificação é feita com base em diversos modelos treinados. Em tópicos anteriores foi discutido o uso do algoritmo AdaBoost, que é um método desse tipo para melhorar o poder de classificadores fracos treinando iterativamente diversos modelos fracos progressivamente com os erros do anterior \cite {explainingadaboost}. Porém, para agregar os modelos usados até agora, iremos implementar algo mais simples, porém seguindo a mesma lógica: Sistemas de Votação. Baseados em \cite{Nagi2013}, usaremos diversos métodos para combinar as classificações dos nossos modelos treinados. Em um, usaremos apenas a classe de saída dos modelos, e posteriormente, as probabilidades (\textit{supports}) para cada uma das classes, que também são saídas dos modelos. Por exemplo, nas redes neurais a saída de um neurônio é a função sigmoide aplicada nas entradas multiplicada pela matriz de pesos da rede, que, por definição é um número entre 0 e 1 que representa uma probabilidade.



\subsection{Votação Simples}

Na votação simples os resultados da classificação de todos os modelos são contabilizados e é escolhido aquele com o maior número de ocorrências entre os classificadores. Os testes foram feitos calculando-se o erro de validação no mesmo dataset de treino com uma quantidade cada vez maior de pontos de treino, estes retirados de um dataset de treino também fixado.


A votação simples foi  primeiramente testada com os algoritmos de Rede Neural, KNN e SVM com zonas escolhidas aleatoriamente do  \textbf{\textit{dataset}} UJIIndoorLoc 



\begin{figure}[!ht]
	\centering
	\caption{Erro de votação simples para uma quantidade crescente de pontos de treino.}
  \includegraphics[width=0.9\textwidth]{VoteError2zonesUCI}
\label{fig:simpleVote}  

\end{figure}


Para comparação, foram calculados os erros de validação independentes de cada um dos algoritmos usados.


\begin{figure}[!ht]
	\centering
	\caption{Erro do algoritmo KNN  para uma quantidade crescente de pontos de treino.}
  \includegraphics[width=0.9\textwidth]{KNNerror2zonesUCI}
\label{fig:crossKNN}  

\end{figure}


\begin{figure}[!ht]
	\centering
	\caption{Erro da Rede Neural  para uma quantidade crescente de pontos de treino.}
  \includegraphics[width=0.9\textwidth]{NNerror2zonesUCI}
\label{fig:crossNN2}  

\end{figure}



\begin{figure}[!ht]
	\centering
	\caption{Erro do algoritmo SVM  para uma quantidade crescente de pontos de treino.}
  \includegraphics[width=0.9\textwidth]{SVMerror2zonesUCI}
\label{fig:crossSVM}  

\end{figure}





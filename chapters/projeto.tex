\chapter{Projeto e Implementação}\label{chp:ml}

\section{Machine Learning}

\subsection{Tratamento dos dados}\label{sec:data1}

\subsubsection{Dados obtidos do Repositório UCI}
	Para grande parte dos testes de \textit{cross-validation}, foi usado o \textit{dataset}  \textit{UJIIndoorLoc} apresentado em \cite{uji}. O \textit{dataset} consiste em diversas medidas de potência de sinal \textit{Wi-Fi} medidas com diversos aparelhos celulares em 3 prédios diferentes de uma faculdade. As medidas estão separadas por prédio, andar e sala. Para os fins dessa monografia, serão realizados testes com medidas sempre de um mesmo andar, afim de classificar as zonas de um mesmo ambiente.  Esse  \textit{dataset} usa a constante $100$ para designar valores não medidos. Para começar o tratamento os substituímos pelo valor de $-120$ (dB), que para todos os fins práticos, é uma medida de potência que representa um valor nulo, já que representa um valor de potência insignificante. E finalmente, antes de serem usados para treinar os modelos, os dados são transformados de modo a ficarem com média 0 e variância 1 por coluna, o que é necessário para evitar comportamentos indesejados dos algoritmos de ML.

A transformação é realizada da seguinte maneira, com $X_j$ representando a j-ésima coluna da matriz de dados, com média $\mu$ e desvio-padrão $\sigma$, para cada elemento $i$ dessa coluna:

\begin{center}
$X_{ij}=\frac{X_{ij}-\mu}{\sigma}$
\end{center}

\subsubsection{Dados do Servidor}

De modo análogo aos dados pegos do Repositório UCI, a matriz de dados é transformada para ter média nula e variância unitária em cada coluna, sendo que antes disso valores nulos são substituídos por $-120$.




\subsection{Formato dos dados tratados}
A matriz de dados, depois de tratada, tem o seguinte formato:

\begin{center}
\begin{blockarray}{cccccc}
$ZoneID$ & $BSSID_1$ & $BSSID_2$ & ... &  $BSSID_n$ \\
\begin{block}{(ccccc)c}
  1&-70 & -92 &   ... &-87&  $ Measure_1$ \\
  2&-89 & -80 & ... & -63&    $Measure_2 $\\
  3&-28 & -120 & ...&   -35& $Measure_3$ \\
   \vdots& \vdots &  \vdots & $\ddots$ &  \vdots &    \vdots \\
  1&-48 & -36 & ... &   -29&  $Measure_n$ \\
\end{block}
\end{blockarray}
\end{center}

Cada coluna representa a medida de uma \textit{BSSID} (i.e. um Roteador), ou seja, uma \textit{feature} para o ML, e cada linha é um ponto de treino (i.e.  uma medida para cada  \textit{BSSID}, nossas \textit{features}).


\subsection{Modelos Usados e \textit{Cross-Validation} de parâmetros }

A chamada \textit{cross-validation} dos modelos de ML é o teste para encontrar os parâmetros ótimos para o treinamento. Um dos métodos escolhidos de \textit{cross-validation} foi o \textit{k-fold}. O método \textit{k-fold} divide o dataset em $K$ subconjuntos de igual tamanho e então um dos conjuntos é usado como validação do treinamento feito pelos $K-1$ subconjuntos restantes. O processo é repetido $K$ vezes e em cada subdivisão possível podem ser usados valores de parâmetros de treino distintos. Para a comparação dos modelos, serão feitos diversos testes com um número crescente de zonas de classificação. Nesse caso, são escolhidas iterativamente e aleatoriamente $n$ zonas do \textit{dataset}  \textit{UJIIndoorLoc}, são pegos todos os pontos associados as $n$ zonas selecionadas. Então, o \textit{dataset}  é separado em 80\% de pontos de treino e 20\% para testes. Para valores de $n$ de 1 a 30 são finalmente medidos as taxas de erro de cada algoritmo e essa informação é apresentada em gráficos.

\subsubsection{KNN : K-Nearest-Neighbors }


Para o algoritmo de KNN, foram feitos dois testes de \textit{cross-validation}. No primeiro, a métrica de distância foi decidida, e no segundo, o número de vizinhos ($K$).
Para que fosse definida a métrica de distância, foi usado o método  \textit{k-fold}  com $K=2$, com cada \textit{fold} utilizando uma métrica diferente. Foram calculados 20 conjuntos diferentes de \textit{folds} e foi tirada a média do erro de validação para cada uma das métricas.


\begin{figure}[H]
\centering
\caption{Erros para uso de Diferentes Distâncias}
 \includegraphics[width=0.7\textwidth]{euclidianManhattanknn21zonas}
\label{fig:euclidian}
\end{figure}


Depois, foi usado o método  \textit{k-fold} com $K=10$ para a decisão do número de vizinhos. Foram testados os valores de 1 até 10 para o número de vizinhos. Na imagem a seguir vemos detalhes desse teste.


\begin{figure}[H]
\centering
\caption{Erro em função do número de vizinhos}
 \includegraphics[width=0.7\textwidth]{CrossValKNN25zonasvalorK}
\label{fig:crossValKNN}
\end{figure}



Podemos concluir então que (1) o erro é menor no geral com a distância de \textit{Manhattan} e (2) embora tenha muita variância envolvida no teste, o valor de K que minimiza o erro fica próximo de 4 vizinhos.


No restante do trabalho foi escolhido o valor de $K=4$ vizinhos.



\subsubsection{Rede Neural}

Para a \textit{cross-validation} das Redes Neurais, também foi usado o método de  \textit{k-fold} com $K=10$. Para cada uns dos\textit{folds} foi testado um número de neurônios em uma  \textit{hidden-layer} única. (Outros testes mostraram não valer a pena para o nosso problema usar mais de uma camada de \textit{hidden layer} ou \textit{deep learning}). Os resultados são mostrados a seguir:



\begin{figure}[H]
	\centering
	\caption{Erro para diversas quantidades de neurônios na rede neural.}
  \includegraphics[width=0.9\textwidth]{CROSSVALE4ZonasNNCERTO}
\label{fig:crossNN}

\end{figure}




Concluímos que o número ideal de neurônios na  \textit{hidden-layer} está próximo de 200. Porém, com estudos e testes mais detalhados ficou claro que as Redes Neurais não são ideias para o nosso projeto, por não conseguirem capturar de forma satisfatória o modelo do nosso problema. Além disso, o algoritmo de \textit{back propagation} se mostra muito mais custoso em relação a memória e processamento se comparado aos outros algoritmos usados no projeto, demorando cerca de 10 vezes mais para o treinamento que todos os outros modelos juntos. Portanto, seu uso foi descartado.

\subsubsection{Árvore de decisão}


Baseado no trabalho apresentado por \cite{comparative}, foi escolhida uma implementação do algoritmo C4.5 \cite{quinlan} em Java, da biblioteca Weka, para serem geradas árvores de decisão. Os métodos porém foram chamados pela interface da Weka para R, chamada RWeka.
A função J48 do Weka foi testada com o os pontos de treino referentes ao primeiro andar do prédio 1 (i.e. BuildingID 1, FloorID 0)  do dataset \textit{UJIIndoorLoc}. Foi levantada a curva de erro de classificação para uma quantidade crescente de pontos de treino (como explicado em 2.3).


\begin{figure}[H]
\centering
\caption{Teste de Validação do Algoritmo C4.5}
 \includegraphics[width=0.9\textwidth]{J48Validacaopredio1andar0}
\label{fig:validationC4.5}
\end{figure}
\setcounter{secnumdepth}{4}

\textbf{Acoplamento com o Algoritmo AdaBoost}\\
\par \textit{Boosting} é a ideia em ML de criar uma predição forte e precisa combinando diversas previsões mais fracas. O algoritmo AdaBoost \cite{adaboost} é um método para melhorar a precisão de classificadores fracos (i.e. \textit{Weak Learners}) por meio de uma votação ponderada que leva em conta o erro de diversos votadores fracos treinados no processo. É provado que o modelo final se torna um classificador forte \cite{explainingadaboost}. Por definição, um classificador fraco é aquele que consistentemente consegue ser melhor que um chute para a classificação (e.g. o erro é menor que 50\% para o caso de duas classes possíveis de classificação).

Também baseados em \cite{comparative} e \cite{comparativeEN}. Usaremos o algoritmo AdaBoost  e sua implementação na biblioteca Weka para melhorar a precisão das árvores de decisão C4.5. O gráfico \ref{fig:comparisonC4.5andAdaBoost} compara a classificação para o mesmo andar do \textit{dataset UJIIndoorLoc} com os mesmos pontos de teste e uma quantidade crescente de pontos de treino, assim como feito no tópico anterior.


\begin{figure}[!h]
\centering
\caption{Comparação do C4.5 com o uso do AdaBoost}
 \includegraphics[width=0.9\textwidth]{J48xADAValidacaopredio1andar0}
\label{fig:comparisonC4.5andAdaBoost}  
\end{figure}


Podemos notar que com um número grande de pontos de treino, obtemos uma melhora sensível de precisão para a classificação, e portanto, no restante do trabalho, iremos usar o algoritmo C4.5 acoplado com o algoritmo AdaBoost.



\subsubsection{Comparação dos Modelos Usados}


Reforçando o que foi explicado em outra sessão, os testes mostrados nas imagens \ref{fig:zonaSMO} à \ref{fig:zonaAda} irão contemplar todos os modelos usados. Os modelos tem seu erro testado para \textit{datasets} com um número crescente de zonas aleatórias a serem classificadas. Todos os testes foram feitos com os dados do primeiro andar do prédio 1 do \textit{dataset UJIIndoorLoc }(i.e. BuildingID 1, FloorID 0).


\begin{figure}[H]
	\centering
	\caption{Erro do algoritmo SMO  para uma quantidade crescente de zonas de classificação.}
  \includegraphics[width=0.8\textwidth]{errorporzonaSMO}
\label{fig:zonaSMO}

\end{figure}



\begin{figure}[H]
	\centering
	\caption{Erro do algoritmo de Redes Neurais  para uma quantidade crescente de zonas de classificação.}
  \includegraphics[width=0.8\textwidth]{errorporzonaNN}
\label{fig:zonaNN}

\end{figure}


\begin{figure}[H]
	\centering
	\caption{Erro do algoritmo KNN para uma quantidade crescente de zonas de classificação.}
  \includegraphics[width=0.8\textwidth]{errorporzonaKNN}
\label{fig:zonaKNN}

\end{figure}



\begin{figure}[H]
	\centering
	\caption{Erro do algoritmo de Árvore de Decisão com e sem o Adaboost  para uma quantidade crescente de zonas de classificação.}
  \includegraphics[width=0.8\textwidth]{errorporzonaJ48+Ada}
\label{fig:zonaAda}

\end{figure}

\subsection{Métodos de Votação}

Os chamados sistemas de \textit{Ensemble Learning} são aqueles em que uma classificação é feita com base em diversos modelos treinados. Em tópicos anteriores foi discutido o uso do algoritmo AdaBoost, que é um método desse tipo para melhorar o poder de classificadores fracos treinando iterativamente diversos modelos fracos progressivamente com os erros do anterior \cite {explainingadaboost}. Porém, para agregar os modelos usados até agora, iremos implementar algo mais simples, porém seguindo a mesma lógica: Sistemas de Votação. Baseados em \cite{Nagi2013}, usaremos diversos métodos para combinar as classificações dos nossos modelos treinados. Em um, foi usado apenas a classe de saída dos modelos, e posteriormente, as probabilidades (\textit{supports}) para cada uma das classes, que também são saídas dos modelos. Esses \textit{supports} podem ser, dependendo do modelo, a probabilidade posterior ou o grau de confiança fornecido pelos algoritmos. Por exemplo, nas redes neurais a saída de um neurônio é a função sigmoide aplicada nas entradas multiplicada pela matriz de pesos da rede, que, por definição, é um número entre 0 e 1 que representa uma probabilidade.




\subsection{Testes com os Métodos de Votação}

Como na sessão de comparação dos modelos, os métodos tem seu erro testado para datasets com um número crescente de zonas aleatórias a serem classificadas. Todos os testes foram feitos com os dados do primeiro andar do prédio 1 do dataset \textit{UJIIndoorLoc} (i.e. BuildingID 1, FloorID 0).




\begin{figure}[!ht]
	\centering
	\caption{Erro do Voto Simples e Voto Ponderado para uma quantidade crescente de zonas de classificação.}
  \includegraphics[width=0.9\textwidth]{errorporzonaVotos}
\label{fig:zonaVotos}

\end{figure}


\section{Aquisição de dados}

Conforme explicado no capítulo \ref{chp:espec}, as informações de redes \textit{Wi-Fi} são obtidas através de um dispositivo Android. Ao tocar no botão de captura num aplicativo instalado no dispositivo, o sistema aguarda o sensor \textit{Wi-Fi} atualizar sua lista de redes disponíveis para conexão, e assim que essa lista é atualizada, os dados obtidos são armazenados. O processo é repetido n vezes, n sendo o número de amostras por ponto determinado pelo usuário. Após isso, os dados são normalizados, seja com uma média simples ou com o uso filtro de Kalman, explicado em \ref{kalman}.

\subsection{Filtro de Kalman}
\label{kalman}
O filtro de Kalman é um método estatístico cujo propósito é utilizar medições de grandezas realizadas ao longo do tempo (contaminadas com ruído e outras incertezas) e gerar resultados que tendem a se aproximar dos valores reais (média da população) das grandezas medidas.
\par
Apesar de normalmente ser utilizado em tempo real, nada impede que o filtro seja aplicado em valores já medidos. Como é possível entender em \cite{7471364}, o filtro de Kalman é um método muito utilizado na obtenção de valores de ondas eletromagnéticas (como as ondas geradas por \textit{Access Points Wi-Fi}, pois estas apresentam muita flutuação nos seus valores associados.
\par
O filtro de Kalman é capaz de fazer uma média ponderada dos sinais lidos, dando um peso menor para aquelas amostras que se afastam muito da média de todos os sinais.
\par Um comparativo entre o uso do filtro de Kalman e uma média aritmética simples existe na sessão \ref{testesinloco}.

\section{Estrutura do servidor}
O \textit{back end} do net.map está hospedado numa instância em nuvem do \textit{Amazon AWS EC2}, serviço de cloud gratuito para estudantes. Nesse servidor se encontram o banco de dados MongoDB, a API Rails e os \textit{scripts} de \textit{Machine Learning} escritos em R, rodando no sistema operacional Ubuntu 14.04, baseado em Linux.
\par
A API Rails, que opera em TCP na porta 3000 é responsável por:
\begin{enumerate}
\item Criar novos usuários
\item Enviar \textit{token} de acesso após o \textit{login} do usuário
\item Criar, modificar e deletar instalações e zonas enviadas pelos usuários
\item Armazenar dados de captura enviados pelo aplicativo Android
\end{enumerate} 

Todos esses dados são salvos na instância do MongoDB rodando no mesmo servidor. As senhas criadas pelos usuários são criptografadas utilizando o Bcrypt, um esquema de \textit{hashing} baseado no Blowfish \cite{provos1999bcrypt}.
\par
Uma biblioteca \textit{open-source} chamada Devise\footnote{Disponível em https://github.com/plataformatec/devise} é responsável pelo gerenciamento dos usuários, suas senhas e seus tokens de acesso. Tudo isso pode ser feito se comunicando com a API através de requisições HTTP. Pode-se considerar que a API aqui apresentada é RESTful, ou seja, implementa todas as suas operações através de uma API REST.
\par
Os scripts de Machine Learning escritos em R rodam em segundo plano como processos \textit{daemonizáveis}, com a ajuda de uma biblioteca \textit{open-source} chamada Pumbler\footnote{https://github.com/trestletech/plumber}. Essa mesma biblioteca também atua como uma API RESTful na porta TCP 2000, possibilitando que o usuário treine os \textit{datasets} no banco de dados e que faça uma teste da zona atual após enviar uma requisição POST contendo dados de potência de sinais \textit{Wi-Fi}. A figura \ref{fig:servidor} mostra como o módulo de ML e a API interagem entre si e com o ambiente externo.


\begin{figure}[H]
	\centering
	\caption{Esquema mostrando como as aplicações no servidor interagem.}
  \includegraphics[width=1\textwidth]{servidor}
\label{fig:servidor}

\end{figure}


